{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c4ddcf",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2679f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import timm\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_DIR = \"/content/results_task1\"; os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 12            # increase to ~20 if time allows\n",
    "LR = 3e-4\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281584ca",
   "metadata": {},
   "source": [
    "1) CIFAR-10 Data & Fixed Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 stats\n",
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "STD  = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "# 32x32 pipeline (ResNet)\n",
    "train_tf_rn = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "test_tf_rn = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "# 224x224 pipeline (ViT)\n",
    "train_tf_vit = transforms.Compose([\n",
    "    transforms.Resize(224, antialias=True),\n",
    "    transforms.RandomCrop(224, padding=8),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "test_tf_vit = transforms.Compose([\n",
    "    transforms.Resize(224, antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "])\n",
    "\n",
    "root = \"/content/data\"\n",
    "full_train = datasets.CIFAR10(root, train=True, download=True, transform=None)\n",
    "test_set   = datasets.CIFAR10(root, train=False, download=True, transform=None)\n",
    "\n",
    "# Fixed split indices (45k train / 5k val)\n",
    "num_train = len(full_train)  # 50,000\n",
    "idx = np.arange(num_train)\n",
    "rng = np.random.default_rng(SEED)\n",
    "rng.shuffle(idx)\n",
    "train_idx, val_idx = idx[:45000], idx[45000:]\n",
    "\n",
    "# Two views of the same split with different transforms\n",
    "class TransformView(torch.utils.data.Dataset):\n",
    "    def __init__(self, base, indices, transform):\n",
    "        self.base = base\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.base[self.indices[i]]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "train_rn = TransformView(full_train, train_idx, train_tf_rn)\n",
    "val_rn   = TransformView(full_train, val_idx,   test_tf_rn)\n",
    "test_rn  = TransformView(test_set,  np.arange(len(test_set)), test_tf_rn)\n",
    "\n",
    "train_vit = TransformView(full_train, train_idx, train_tf_vit)\n",
    "val_vit   = TransformView(full_train, val_idx,   test_tf_vit)\n",
    "test_vit  = TransformView(test_set,  np.arange(len(test_set)), test_tf_vit)\n",
    "\n",
    "train_loader_rn = DataLoader(train_rn, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader_rn   = DataLoader(val_rn,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader_rn  = DataLoader(test_rn,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "train_loader_vit = DataLoader(train_vit, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader_vit   = DataLoader(val_vit,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader_vit  = DataLoader(test_vit,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886ee38",
   "metadata": {},
   "source": [
    "2) Models (ResNet-50 & ViT-S/16, pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e18dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50(num_classes=10, pretrained=True):\n",
    "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def build_vit_s16(num_classes=10, pretrained=True):\n",
    "    m = timm.create_model('vit_small_patch16_224', pretrained=pretrained)\n",
    "    m.head = nn.Linear(m.head.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "resnet = build_resnet50().to(device)\n",
    "vit    = build_vit_s16().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471dbd1d",
   "metadata": {},
   "source": [
    "3) Train/Eval Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b76724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, opt):\n",
    "    model.train()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        loss.backward(); opt.step()\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        pred = out.argmax(1); total += y.size(0); correct += (pred == y).sum().item()\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_acc(model, loader):\n",
    "    model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        pred = out.argmax(1); total += y.size(0); correct += (pred == y).sum().item()\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "def fit(model, train_loader, val_loader, test_loader, tag):\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    best_val = 0.0\n",
    "    history = []\n",
    "    best_path = f\"{SAVE_DIR}/{tag}_best.pth\"\n",
    "\n",
    "    for e in range(1, EPOCHS+1):\n",
    "        tr_loss, tr_acc = train_epoch(model, train_loader, opt)\n",
    "        va_loss, va_acc = eval_acc(model, val_loader)\n",
    "        te_loss, te_acc = eval_acc(model, test_loader)\n",
    "        history.append((e, tr_loss, tr_acc, va_loss, va_acc, te_loss, te_acc))\n",
    "        print(f\"[{tag}] Ep{e:02d} | train {tr_loss:.3f}/{tr_acc:.3f} | val {va_loss:.3f}/{va_acc:.3f} | test {te_loss:.3f}/{te_acc:.3f}\")\n",
    "\n",
    "        if va_acc > best_val:\n",
    "            best_val = va_acc\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    # Load best-by-val and report final test\n",
    "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    final_test_loss, final_test_acc = eval_acc(model, test_loader)\n",
    "    print(f\"[{tag}] Best-on-val checkpoint -> test acc: {final_test_acc:.4f}\")\n",
    "    return history, best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_rn, ckpt_rn = fit(resnet, train_loader_rn, val_loader_rn, test_loader_rn, tag=\"resnet50_cifar\")\n",
    "hist_vt, ckpt_vt = fit(vit,    train_loader_vit, val_loader_vit, test_loader_vit, tag=\"vit_s16_cifar\")\n",
    "\n",
    "print(\"Saved:\", ckpt_rn, ckpt_vt)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
