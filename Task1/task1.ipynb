{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "73c4ddcf",
      "metadata": {
        "id": "73c4ddcf"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2679f3c",
      "metadata": {
        "id": "c2679f3c"
      },
      "outputs": [],
      "source": [
        "import os, random, math\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import timm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SAVE_DIR = \"/content/results_task1\"; os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "BATCH_SIZE_RN = 256\n",
        "BATCH_SIZE_VIT = 64 # Reduced batch size for ViT\n",
        "\n",
        "EPOCHS = 12            # increase to ~20 if time allows\n",
        "LR = 3e-4\n",
        "NUM_WORKERS = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281584ca",
      "metadata": {
        "id": "281584ca"
      },
      "source": [
        "## 1) CIFAR-10 Data & Fixed Train/Val/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c8c5e82e",
      "metadata": {
        "id": "c8c5e82e"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 stats\n",
        "MEAN = (0.4914, 0.4822, 0.4465)\n",
        "STD  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# 32x32 pipeline (ResNet)\n",
        "train_tf_rn = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "test_tf_rn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "# 224x224 pipeline (ViT)\n",
        "train_tf_vit = transforms.Compose([\n",
        "    transforms.Resize(224, antialias=True),\n",
        "    transforms.RandomCrop(224, padding=8),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "test_tf_vit = transforms.Compose([\n",
        "    transforms.Resize(224, antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "root = \"/content/data\"\n",
        "full_train = datasets.CIFAR10(root, train=True, download=True, transform=None)\n",
        "test_set   = datasets.CIFAR10(root, train=False, download=True, transform=None)\n",
        "\n",
        "# Fixed split indices (45k train / 5k val)\n",
        "num_train = len(full_train)  # 50,000\n",
        "idx = np.arange(num_train)\n",
        "rng = np.random.default_rng(SEED)\n",
        "rng.shuffle(idx)\n",
        "train_idx, val_idx = idx[:45000], idx[45000:]\n",
        "\n",
        "# Two views of the same split with different transforms\n",
        "class TransformView(torch.utils.data.Dataset):\n",
        "    def __init__(self, base, indices, transform):\n",
        "        self.base = base\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.indices)\n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.base[self.indices[i]]\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "train_rn = TransformView(full_train, train_idx, train_tf_rn)\n",
        "val_rn   = TransformView(full_train, val_idx,   test_tf_rn)\n",
        "test_rn  = TransformView(test_set,  np.arange(len(test_set)), test_tf_rn)\n",
        "\n",
        "train_vit = TransformView(full_train, train_idx, train_tf_vit)\n",
        "val_vit   = TransformView(full_train, val_idx,   test_tf_vit)\n",
        "test_vit  = TransformView(test_set,  np.arange(len(test_set)), test_tf_vit)\n",
        "\n",
        "train_loader_rn = DataLoader(train_rn, batch_size=BATCH_SIZE_RN, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader_rn   = DataLoader(val_rn,   batch_size=BATCH_SIZE_RN, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader_rn  = DataLoader(test_rn,  batch_size=BATCH_SIZE_RN, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "train_loader_vit = DataLoader(train_vit, batch_size=BATCH_SIZE_VIT, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader_vit   = DataLoader(val_vit,   batch_size=BATCH_SIZE_VIT, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader_vit  = DataLoader(test_vit,  batch_size=BATCH_SIZE_VIT, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e886ee38",
      "metadata": {
        "id": "e886ee38"
      },
      "source": [
        "## 2) Models (ResNet-50 & ViT-S/16, pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "09e18dc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09e18dc8",
        "outputId": "7b7ccf97-39c9-458c-839b-543d9813dfd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def build_resnet50(num_classes=10, pretrained=True):\n",
        "    m = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
        "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "def build_vit_s16(num_classes=10, pretrained=True):\n",
        "    m = timm.create_model('vit_small_patch16_224', pretrained=pretrained)\n",
        "    m.head = nn.Linear(m.head.in_features, num_classes)\n",
        "    return m\n",
        "\n",
        "resnet = build_resnet50().to(device)\n",
        "vit    = build_vit_s16().to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471dbd1d",
      "metadata": {
        "id": "471dbd1d"
      },
      "source": [
        "## 3) Train/Eval Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7b76724",
      "metadata": {
        "id": "f7b76724"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, opt):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = F.cross_entropy(out, y)\n",
        "        loss.backward(); opt.step()\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        pred = out.argmax(1); total += y.size(0); correct += (pred == y).sum().item()\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_acc(model, loader):\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out = model(x)\n",
        "        loss = F.cross_entropy(out, y)\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        pred = out.argmax(1); total += y.size(0); correct += (pred == y).sum().item()\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "def fit(model, train_loader, val_loader, test_loader, tag):\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    best_val = 0.0\n",
        "    history = []\n",
        "    best_path = f\"{SAVE_DIR}/{tag}_best.pth\"\n",
        "\n",
        "    for e in range(1, EPOCHS+1):\n",
        "        tr_loss, tr_acc = train_epoch(model, train_loader, opt)\n",
        "        va_loss, va_acc = eval_acc(model, val_loader)\n",
        "        te_loss, te_acc = eval_acc(model, test_loader)\n",
        "        history.append((e, tr_loss, tr_acc, va_loss, va_acc, te_loss, te_acc))\n",
        "        print(f\"[{tag}] Ep{e:02d} | train {tr_loss:.3f}/{tr_acc:.3f} | val {va_loss:.3f}/{va_acc:.3f} | test {te_loss:.3f}/{te_acc:.3f}\")\n",
        "\n",
        "        if va_acc > best_val:\n",
        "            best_val = va_acc\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "\n",
        "    # Load best-by-val and report final test\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    final_test_loss, final_test_acc = eval_acc(model, test_loader)\n",
        "    print(f\"[{tag}] Best-on-val checkpoint -> test acc: {final_test_acc:.4f}\")\n",
        "    return history, best_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c40ebd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c40ebd0",
        "outputId": "77355910-8da8-47ee-f2f4-6cf3558562ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[resnet50_cifar] Ep01 | train 1.173/0.596 | val 0.565/0.806 | test 0.593/0.797\n",
            "[resnet50_cifar] Ep02 | train 0.543/0.815 | val 0.431/0.854 | test 0.452/0.847\n",
            "[resnet50_cifar] Ep03 | train 0.413/0.857 | val 0.420/0.857 | test 0.430/0.856\n",
            "[resnet50_cifar] Ep04 | train 0.343/0.881 | val 0.368/0.876 | test 0.395/0.864\n",
            "[resnet50_cifar] Ep05 | train 0.289/0.899 | val 0.350/0.885 | test 0.375/0.874\n",
            "[resnet50_cifar] Ep06 | train 0.255/0.911 | val 0.346/0.888 | test 0.347/0.885\n",
            "[resnet50_cifar] Ep07 | train 0.221/0.924 | val 0.345/0.886 | test 0.373/0.882\n",
            "[resnet50_cifar] Ep08 | train 0.203/0.930 | val 0.356/0.891 | test 0.374/0.884\n",
            "[resnet50_cifar] Ep09 | train 0.179/0.938 | val 0.364/0.885 | test 0.371/0.886\n",
            "[resnet50_cifar] Ep10 | train 0.163/0.944 | val 0.348/0.893 | test 0.380/0.884\n",
            "[resnet50_cifar] Ep11 | train 0.150/0.948 | val 0.346/0.895 | test 0.375/0.887\n",
            "[resnet50_cifar] Ep12 | train 0.133/0.953 | val 0.349/0.897 | test 0.364/0.891\n"
          ]
        }
      ],
      "source": [
        "hist_rn, ckpt_rn = fit(resnet, train_loader_rn, val_loader_rn, test_loader_rn, tag=\"resnet50_cifar\")\n",
        "hist_vt, ckpt_vt = fit(vit,    train_loader_vit, val_loader_vit, test_loader_vit, tag=\"vit_s16_cifar\")\n",
        "\n",
        "print(\"Saved:\", ckpt_rn, ckpt_vt)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}